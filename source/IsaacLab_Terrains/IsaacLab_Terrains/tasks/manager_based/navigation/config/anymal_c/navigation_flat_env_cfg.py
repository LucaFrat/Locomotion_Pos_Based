# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

import math
import os

import isaaclab.sim as sim_utils
from isaaclab.assets import AssetBaseCfg
from isaaclab.envs import ManagerBasedRLEnvCfg
from isaaclab.managers import EventTermCfg as EventTerm
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.managers import CurriculumTermCfg as CurrTerm
from isaaclab.managers import RewardTermCfg as RewTerm
from isaaclab.managers import SceneEntityCfg
from isaaclab.managers import TerminationTermCfg as DoneTerm
from isaaclab.utils import configclass
from isaaclab.utils.assets import ISAACLAB_NUCLEUS_DIR

import IsaacLab_Terrains.tasks.manager_based.navigation.mdp as mdp
from IsaacLab_Terrains.tasks.manager_based.locomotion.velocity.config.anymal_c.flat_env_cfg import AnymalCFlatEnvCfg
import IsaacLab_Terrains.tasks.manager_based.navigation.mdp.commands as obstacle_cmd


LOW_LEVEL_ENV_CFG = AnymalCFlatEnvCfg()




@configclass
class EventCfg:
    """Configuration for events."""

    reset_cone_pos = EventTerm(
        func=mdp.reset_cone_pos_donut,
        mode="reset",
        # min_step_count_between_reset=50_000,
        params={
            "asset_cfg": SceneEntityCfg("cone"), # Must match the name in MySceneCfg
            "radius_range": (1.5, 2.0),
        },
    )
    reset_base = EventTerm(
        func=mdp.reset_root_state_uniform,
        mode="reset",
        params={
            "pose_range": {"x": (-0.2, 0.2), "y": (-0.2, 0.2), "yaw": (-3.14, 3.14)},
            "velocity_range": {
                "x": (-0.0, 0.0),
                "y": (-0.0, 0.0),
                "z": (-0.0, 0.0),
                "roll": (-0.0, 0.0),
                "pitch": (-0.0, 0.0),
                "yaw": (-0.0, 0.0),
            },
        },
    )


@configclass
class ActionsCfg:
    """Action terms for the MDP."""

    pre_trained_policy_action: mdp.PreTrainedPolicyActionCfg = mdp.PreTrainedPolicyActionCfg(
        asset_name="robot",
        policy_path=f"{ISAACLAB_NUCLEUS_DIR}/Policies/ANYmal-C/Blind/policy.pt",
        low_level_decimation=4,
        low_level_actions=LOW_LEVEL_ENV_CFG.actions.joint_pos,
        low_level_observations=LOW_LEVEL_ENV_CFG.observations.policy,
    )


@configclass
class ObservationsCfg:
    """Observation specifications for the MDP."""

    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group."""

        # observation terms (order preserved)
        base_lin_vel = ObsTerm(func=mdp.base_lin_vel)
        projected_gravity = ObsTerm(func=mdp.projected_gravity)
        pose_command = ObsTerm(func=mdp.generated_commands, params={"command_name": "pose_command"})

        cone_pos = ObsTerm(
            func=mdp.cone_position_b,
            params={
                "robot_cfg": SceneEntityCfg("robot"),
                "cone_cfg": SceneEntityCfg("cone"),
            },
        )

    # observation groups
    policy: PolicyCfg = PolicyCfg()


@configclass
class RewardsCfg:
    """Reward terms for the MDP."""

    termination_penalty = RewTerm(func=mdp.is_terminated, weight=-400.0)

    position_tracking = RewTerm(
        func=mdp.position_command_error_tanh,
        weight=0.5,
        params={"std": 2.0, "command_name": "pose_command"},
    )

    position_tracking_fine_grained = RewTerm(
        func=mdp.position_command_error_tanh,
        weight=0.2,
        params={"std": 0.2, "command_name": "pose_command"},
    )

    # orientation_tracking = RewTerm(
    #     func=mdp.heading_command_error_abs,
    #     weight=-0.2,
    #     params={"command_name": "pose_command"},
    # )
    cone_too_close = RewTerm(
        func=mdp.cone_proximity_penalty,
        weight=-1.0,
        params={
            "robot_cfg": SceneEntityCfg("robot"),
            "cone_cfg": SceneEntityCfg("cone"),
            "threshold": 0.4, # If closer than 0.6m, start penalizing
        },
    )
    progress = RewTerm(
        func=mdp.progress_toward_goal,
        weight=0.5, # Positive signal for moving in the right direction
        params={"command_name": "pose_command"},
    )

    # penalize high velocity commands to encourage efficiency
    # action_l2 = RewTerm(func=mdp.action_l2, weight=-0.05)

    # penalize jerky command changes
    # action_rate_l2 = RewTerm(func=mdp.action_rate_l2, weight=-0.05)

    # face_target = RewTerm(
    #     func=mdp.face_target,
    #     weight= -0.1,
    #     params={"command_name": "pose_command"}
    # )


@configclass
class CommandsCfg:
    """Command terms for the MDP."""

    pose_command = obstacle_cmd.ObstacleBlockedPoseCommandCfg(
        asset_name="robot",
        obstacle_cfg=SceneEntityCfg("cone"),
        simple_heading=False,
        resampling_time_range=(8.0, 8.0),
        debug_vis=True,
        goal_distance_behind_obstacle=(1.0, 2.0),
        goal_pose_angle_range=(-1.507, 1.507),
        ranges=mdp.UniformPose2dCommandCfg.Ranges(pos_x=(-3.0, 3.0), pos_y=(-3.0, 3.0), heading=(-math.pi, math.pi)),
    )



@configclass
class TerminationsCfg:
    """Termination terms for the MDP."""

    time_out = DoneTerm(func=mdp.time_out, time_out=True)
    base_contact = DoneTerm(
        func=mdp.illegal_contact,
        params={"sensor_cfg": SceneEntityCfg("contact_forces", body_names="base"), "threshold": 1.0},
    )

@configclass
class CurriculumCfg:
    """Curriculum terms for the MDP."""
    goal_distance = CurrTerm(
        func=mdp.distance_level,
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "command_name": "pose_command",
        }
    )
    obstacle_angle = CurrTerm(
        func=mdp.obstacle_angle_level,
        params={"command_name": "pose_command"},
    )



@configclass
class NavigationFlatEnvCfg(ManagerBasedRLEnvCfg):
    """Configuration for the navigation environment."""

    # environment settings
    scene: SceneEntityCfg = LOW_LEVEL_ENV_CFG.scene
    actions: ActionsCfg = ActionsCfg()
    observations: ObservationsCfg = ObservationsCfg()
    events: EventCfg = EventCfg()
    # mdp settings
    commands: CommandsCfg = CommandsCfg()
    rewards: RewardsCfg = RewardsCfg()
    terminations: TerminationsCfg = TerminationsCfg()
    curriculum: CurriculumCfg = CurriculumCfg()


    def __post_init__(self):
        """Post initialization."""

        self.sim.dt = LOW_LEVEL_ENV_CFG.sim.dt
        self.sim.render_interval = LOW_LEVEL_ENV_CFG.decimation
        self.decimation = LOW_LEVEL_ENV_CFG.decimation * 10
        self.episode_length_s = self.commands.pose_command.resampling_time_range[1]

        if self.scene.height_scanner is not None:
            self.scene.height_scanner.update_period = (
                self.actions.pre_trained_policy_action.low_level_decimation * self.sim.dt
            )
        if self.scene.contact_forces is not None:
            self.scene.contact_forces.update_period = self.sim.dt


class NavigationEnvCfg_PLAY(NavigationFlatEnvCfg):
    def __post_init__(self) -> None:
        # post init of parent
        super().__post_init__()

        # make a smaller scene for play
        self.scene.num_envs = 1
        self.scene.env_spacing = 2.5
        # disable randomization for play
        self.observations.policy.enable_corruption = False
